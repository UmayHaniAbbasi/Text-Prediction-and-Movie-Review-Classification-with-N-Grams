{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGku1026Gl5h",
        "outputId": "32dc1391-adba-455e-aa23-6d77b143b16f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original sentence: this movie is great\n",
            "Context: ['this', 'movie'] -> Predicted next word: 'was', Actual word: 'great'\n",
            "Predicted sentence: this movie was\n",
            "Accuracy: 2/3 words correct\n",
            "\n",
            "Original sentence: the acting was terrible\n",
            "Context: ['acting', 'was'] -> Predicted next word: 'terrible', Actual word: 'terrible'\n",
            "Predicted sentence: acting was terrible\n",
            "Accuracy: 3/3 words correct\n",
            "\n",
            "Original sentence: the story was very interesting\n",
            "Context: ['story', 'was'] -> Predicted next word: 'so', Actual word: 'very'\n",
            "Context: ['was', 'so'] -> Predicted next word: 'bad', Actual word: 'interesting'\n",
            "Predicted sentence: story was so bad\n",
            "Accuracy: 2/4 words correct\n",
            "\n",
            "Original sentence: I didn't like the direction\n",
            "Context: ['i', 'didnt'] -> Predicted next word: 'like', Actual word: 'like'\n",
            "Context: ['didnt', 'like'] -> Predicted next word: 'this', Actual word: 'direction'\n",
            "Predicted sentence: i didnt like this\n",
            "Accuracy: 3/4 words correct\n"
          ]
        }
      ],
      "source": [
        "#                      TEXT PREDICTION\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "# Preprocessing function to clean the text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# Tokenize the text into words\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Stopword Removal\n",
        "stopwords = set(['the', 'is', 'in', 'it', 'of', 'and', 'to', 'a'])\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    return [token for token in tokens if token not in stopwords]\n",
        "\n",
        "# Function to build n-gram models\n",
        "def build_ngram_model(tokens, n):\n",
        "    ngram_model = defaultdict(Counter)\n",
        "    for i in range(len(tokens) - n):\n",
        "        ngram = tuple(tokens[i:i + n])\n",
        "        next_word = tokens[i + n]\n",
        "        ngram_model[ngram][next_word] += 1\n",
        "    return ngram_model\n",
        "\n",
        "# Add-one Smoothing\n",
        "def add_one_smoothing(ngram_model, vocab_size):\n",
        "    smoothed_model = defaultdict(Counter)\n",
        "    for context, word_counts in ngram_model.items():\n",
        "        total_count = sum(word_counts.values()) + vocab_size\n",
        "        for word, count in word_counts.items():\n",
        "            smoothed_model[context][word] = (count + 1) / total_count\n",
        "        smoothed_model[context]['<UNK>'] = 1 / total_count\n",
        "    return smoothed_model\n",
        "\n",
        "# Backoff Model for Prediction\n",
        "def backoff_ngram_predict(unigram_model, bigram_model, trigram_model, context):\n",
        "    if len(context) == 2 and tuple(context) in trigram_model:\n",
        "        return max(trigram_model[tuple(context)], key=trigram_model[tuple(context)].get)\n",
        "    elif len(context) >= 1 and tuple(context[-1:]) in bigram_model:\n",
        "        return max(bigram_model[tuple(context[-1:])], key=bigram_model[tuple(context[-1:])].get)\n",
        "    else:\n",
        "        return max(unigram_model, key=unigram_model.get)\n",
        "\n",
        "# Model Accuracy Evaluation\n",
        "def evaluate_and_display_model(test_sentences, unigram_model, bigram_model, trigram_model):\n",
        "    for sentence in test_sentences:\n",
        "        print(f\"\\nOriginal sentence: {sentence}\")\n",
        "        tokens = tokenize(preprocess_text(sentence))\n",
        "        tokens = remove_stopwords(tokens)\n",
        "        predicted_sentence = tokens[:2]\n",
        "\n",
        "        # Predict each word one by one using backoff model\n",
        "        for i in range(2, len(tokens)):\n",
        "            context = predicted_sentence[-2:]\n",
        "            predicted_word = backoff_ngram_predict(unigram_model, bigram_model, trigram_model, context)\n",
        "            predicted_sentence.append(predicted_word)\n",
        "            print(f\"Context: {context} -> Predicted next word: '{predicted_word}', Actual word: '{tokens[i]}'\")\n",
        "\n",
        "        # Show the predicted sentence\n",
        "        predicted_sentence_str = ' '.join(predicted_sentence)\n",
        "        print(f\"Predicted sentence: {predicted_sentence_str}\")\n",
        "        print(f\"Accuracy: {sum(1 for a, b in zip(predicted_sentence, tokens) if a == b)}/{len(tokens)} words correct\")\n",
        "\n",
        "\n",
        "file_path = '/IMDB Dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
        "df['tokens'] = df['cleaned_review'].apply(tokenize)\n",
        "df['tokens'] = df['tokens'].apply(remove_stopwords)\n",
        "\n",
        "# Combine all tokens for the n-gram model training\n",
        "all_tokens = [token for sublist in df['tokens'] for token in sublist]\n",
        "\n",
        "\n",
        "unigram_model = Counter(all_tokens)\n",
        "bigram_model = build_ngram_model(all_tokens, 1)\n",
        "trigram_model = build_ngram_model(all_tokens, 2)\n",
        "\n",
        "# Smoothing\n",
        "vocab_size = len(set(all_tokens))\n",
        "bigram_model_smoothed = add_one_smoothing(bigram_model, vocab_size)\n",
        "trigram_model_smoothed = add_one_smoothing(trigram_model, vocab_size)\n",
        "\n",
        "#test data for evaluation\n",
        "test_data = [\n",
        "    \"this movie is great\",\n",
        "    \"the acting was terrible\",\n",
        "    \"the story was very interesting\",\n",
        "    \"I didn't like the direction\"\n",
        "]\n",
        "\n",
        "\n",
        "evaluate_and_display_model(test_data, unigram_model, bigram_model, trigram_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#                                TEXT CLASSIFICATION\n",
        "\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "import math\n",
        "\n",
        "# Preprocessing function to clean the text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# Tokenize the text into words\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Function to build n-gram models for each class\n",
        "def build_ngram_model_by_class(reviews, n):\n",
        "    ngram_model = defaultdict(Counter)\n",
        "    for review in reviews:\n",
        "        tokens = tokenize(preprocess_text(review))\n",
        "        for i in range(len(tokens) - n):\n",
        "            ngram = tuple(tokens[i:i + n])\n",
        "            next_word = tokens[i + n]\n",
        "            ngram_model[ngram][next_word] += 1\n",
        "    return ngram_model\n",
        "\n",
        "import math\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Bayesian Classification\n",
        "def bayesian_classification(review, pos_model, neg_model, pos_prior, neg_prior, n):\n",
        "    tokens = tokenize(preprocess_text(review))\n",
        "\n",
        "    pos_prob = math.log(pos_prior)\n",
        "    neg_prob = math.log(neg_prior)\n",
        "\n",
        "    print(f\"\\nReview: '{review}'\")\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "\n",
        "\n",
        "    for i in range(len(tokens) - n + 1):\n",
        "        ngram = tuple(tokens[i:i + n])\n",
        "\n",
        "\n",
        "        total_pos_ngrams = sum(sum(counter.values()) for counter in pos_model.values())\n",
        "        total_neg_ngrams = sum(sum(counter.values()) for counter in neg_model.values())\n",
        "\n",
        "        # count of the n-gram in the positive and negative models\n",
        "        pos_ngram_count = pos_model[ngram] if ngram in pos_model else Counter()\n",
        "        neg_ngram_count = neg_model[ngram] if ngram in neg_model else Counter()\n",
        "\n",
        "        # Adding 1 for smoothing\n",
        "        pos_ngram_prob = math.log((sum(pos_ngram_count.values()) + 1) / (total_pos_ngrams + len(pos_model)))\n",
        "        neg_ngram_prob = math.log((sum(neg_ngram_count.values()) + 1) / (total_neg_ngrams + len(neg_model)))\n",
        "\n",
        "        # log probabilities\n",
        "        pos_prob += pos_ngram_prob\n",
        "        neg_prob += neg_ngram_prob\n",
        "\n",
        "        # Display calculations\n",
        "        print(f\"Context: {ngram}\")\n",
        "        print(f\"  Positive class log probability: {pos_ngram_prob}\")\n",
        "        print(f\"  Negative class log probability: {neg_ngram_prob}\")\n",
        "\n",
        "    print(f\"\\nFinal log probabilities:\")\n",
        "    print(f\"  Positive class: {pos_prob}\")\n",
        "    print(f\"  Negative class: {neg_prob}\")\n",
        "\n",
        "\n",
        "    predicted_label = 'positive' if pos_prob > neg_prob else 'negative'\n",
        "    print(f\"Predicted label: {predicted_label}\")\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "\n",
        "def evaluate_model(test_data, pos_model, neg_model, pos_prior, neg_prior, n):\n",
        "    correct = 0\n",
        "    total = len(test_data)\n",
        "\n",
        "    print(\"\\n==== Model Evaluation Start ====\\n\")\n",
        "\n",
        "    for review, actual_label in test_data:\n",
        "        print(f\"Actual label: {actual_label}\")\n",
        "        predicted_label = bayesian_classification(review, pos_model, neg_model, pos_prior, neg_prior, n)\n",
        "        print(f\"  ==> Predicted label: {predicted_label}, Actual label: {actual_label}\\n\")\n",
        "\n",
        "        if predicted_label == actual_label:\n",
        "            print(\"  ==> Correct!\\n\")\n",
        "            correct += 1\n",
        "        else:\n",
        "            print(\"  ==> Incorrect!\\n\")\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"==== Model Evaluation Complete ====\")\n",
        "    print(f\"Total Correct: {correct} / {total}\")\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "# Sample test data for evaluation\n",
        "test_data = [\n",
        "    (\"I loved the acting and the storyline\", 'positive'),\n",
        "    (\"The movie was terrible and boring\", 'negative'),\n",
        "    (\"An excellent performance by the cast\", 'positive'),\n",
        "    (\"I hated the film, it was the worst\", 'negative')\n",
        "]\n",
        "\n",
        "\n",
        "evaluate_model(test_data, pos_ngram_model, neg_ngram_model, pos_prior, neg_prior, n)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV0Ccu2WRoW5",
        "outputId": "7629b1cb-5aed-4600-f2d1-335b0f570101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Model Evaluation Start ====\n",
            "\n",
            "Actual label: positive\n",
            "\n",
            "Review: 'I loved the acting and the storyline'\n",
            "Tokens: ['i', 'loved', 'the', 'acting', 'and', 'the', 'storyline']\n",
            "Context: ('i', 'loved')\n",
            "  Positive class log probability: -8.865629254239504\n",
            "  Negative class log probability: -10.110322130841297\n",
            "Context: ('loved', 'the')\n",
            "  Positive class log probability: -9.652902715491539\n",
            "  Negative class log probability: -10.531702694255362\n",
            "Context: ('the', 'acting')\n",
            "  Positive class log probability: -8.295771356427476\n",
            "  Negative class log probability: -7.684123081880075\n",
            "Context: ('acting', 'and')\n",
            "  Positive class log probability: -9.677053175723822\n",
            "  Negative class log probability: -9.309186312217257\n",
            "Context: ('and', 'the')\n",
            "  Positive class log probability: -6.218146091879847\n",
            "  Negative class log probability: -6.359374309171852\n",
            "Context: ('the', 'storyline')\n",
            "  Positive class log probability: -10.109546956219907\n",
            "  Negative class log probability: -9.846609248502512\n",
            "\n",
            "Final log probabilities:\n",
            "  Positive class: -53.512196730542044\n",
            "  Negative class: -54.5344649574283\n",
            "Predicted label: positive\n",
            "  ==> Predicted label: positive, Actual label: positive\n",
            "\n",
            "  ==> Correct!\n",
            "\n",
            "Actual label: negative\n",
            "\n",
            "Review: 'The movie was terrible and boring'\n",
            "Tokens: ['the', 'movie', 'was', 'terrible', 'and', 'boring']\n",
            "Context: ('the', 'movie')\n",
            "  Positive class log probability: -6.607554258103184\n",
            "  Negative class log probability: -6.314793518042518\n",
            "Context: ('movie', 'was')\n",
            "  Positive class log probability: -8.504915094917905\n",
            "  Negative class log probability: -7.856264078741912\n",
            "Context: ('was', 'terrible')\n",
            "  Positive class log probability: -13.14724342887293\n",
            "  Negative class log probability: -10.202129680094421\n",
            "Context: ('terrible', 'and')\n",
            "  Positive class log probability: -12.695258305129872\n",
            "  Negative class log probability: -10.627012874059686\n",
            "Context: ('and', 'boring')\n",
            "  Positive class log probability: -11.979638268717869\n",
            "  Negative class log probability: -10.273873584953261\n",
            "\n",
            "Final log probabilities:\n",
            "  Positive class: -53.62775653630171\n",
            "  Negative class: -45.96722091645175\n",
            "Predicted label: negative\n",
            "  ==> Predicted label: negative, Actual label: negative\n",
            "\n",
            "  ==> Correct!\n",
            "\n",
            "Actual label: positive\n",
            "\n",
            "Review: 'An excellent performance by the cast'\n",
            "Tokens: ['an', 'excellent', 'performance', 'by', 'the', 'cast']\n",
            "Context: ('an', 'excellent')\n",
            "  Positive class log probability: -8.944685282010596\n",
            "  Negative class log probability: -10.531702694255362\n",
            "Context: ('excellent', 'performance')\n",
            "  Positive class log probability: -11.725857747941768\n",
            "  Negative class log probability: -13.054761110007737\n",
            "Context: ('performance', 'by')\n",
            "  Positive class log probability: -10.22561912747266\n",
            "  Negative class log probability: -11.177843832439375\n",
            "Context: ('by', 'the')\n",
            "  Positive class log probability: -7.253234217915661\n",
            "  Negative class log probability: -7.332920448096507\n",
            "Context: ('the', 'cast')\n",
            "  Positive class log probability: -8.597888021991235\n",
            "  Negative class log probability: -8.63592050221114\n",
            "\n",
            "Final log probabilities:\n",
            "  Positive class: -47.44043157789187\n",
            "  Negative class: -51.42629576757007\n",
            "Predicted label: positive\n",
            "  ==> Predicted label: positive, Actual label: positive\n",
            "\n",
            "  ==> Correct!\n",
            "\n",
            "Actual label: negative\n",
            "\n",
            "Review: 'I hated the film, it was the worst'\n",
            "Tokens: ['i', 'hated', 'the', 'film', 'it', 'was', 'the', 'worst']\n",
            "Context: ('i', 'hated')\n",
            "  Positive class log probability: -12.454096248312984\n",
            "  Negative class log probability: -10.469506486385455\n",
            "Context: ('hated', 'the')\n",
            "  Positive class log probability: -12.608246928140241\n",
            "  Negative class log probability: -11.528704806512689\n",
            "Context: ('the', 'film')\n",
            "  Positive class log probability: -6.294246085840015\n",
            "  Negative class log probability: -6.452897134237673\n",
            "Context: ('film', 'it')\n",
            "  Positive class log probability: -9.265679630929492\n",
            "  Negative class log probability: -9.425985579963507\n",
            "Context: ('it', 'was')\n",
            "  Positive class log probability: -6.8441013037569505\n",
            "  Negative class log probability: -6.660278891768071\n",
            "Context: ('was', 'the')\n",
            "  Positive class log probability: -8.008927155830326\n",
            "  Negative class log probability: -7.732076387011407\n",
            "Context: ('the', 'worst')\n",
            "  Positive class log probability: -10.056200975514614\n",
            "  Negative class log probability: -7.517164410236088\n",
            "\n",
            "Final log probabilities:\n",
            "  Positive class: -66.22464550888458\n",
            "  Negative class: -60.479760876674845\n",
            "Predicted label: negative\n",
            "  ==> Predicted label: negative, Actual label: negative\n",
            "\n",
            "  ==> Correct!\n",
            "\n",
            "==== Model Evaluation Complete ====\n",
            "Total Correct: 4 / 4\n",
            "Accuracy: 100.00%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}